#!/usr/bin/env python3
"""
Analyze current prefecture data and create mapping for prefecture IDs.
"""

import csv
from collections import Counter
from pathlib import Path

def analyze_prefecture_data():
    """Analyze existing prefecture data in stations.csv"""
    csv_path = Path("data/stations.csv")
    
    if not csv_path.exists():
        print(f"âŒ {csv_path} not found")
        return
    
    prefecture_counts = Counter()
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            prefecture = row.get('prefecture', '').strip()
            if prefecture:
                prefecture_counts[prefecture] += 1
    
    print("Current Prefecture Distribution:")
    print("=" * 50)
    for prefecture, count in prefecture_counts.most_common():
        print(f"{prefecture}: {count} stations")
    
    return prefecture_counts

def create_prefecture_mapping():
    """Create standard prefecture ID mapping"""
    # JIS X 0401 prefecture codes (ISO 3166-2:JP)
    prefecture_mapping = {
        "åŒ—æµ·é“": "01",
        "é’æ£®çœŒ": "02", 
        "å²©æ‰‹çœŒ": "03",
        "å®®åŸçœŒ": "04",
        "ç§‹ç”°çœŒ": "05",
        "å±±å½¢çœŒ": "06",
        "ç¦å³¶çœŒ": "07",
        "èŒ¨åŸçœŒ": "08",
        "æ ƒæœ¨çœŒ": "09",
        "ç¾¤é¦¬çœŒ": "10",
        "åŸ¼ç‰çœŒ": "11",
        "åƒè‘‰çœŒ": "12",
        "æ±äº¬éƒ½": "13",
        "ç¥å¥ˆå·çœŒ": "14",
        "æ–°æ½ŸçœŒ": "15",
        "å¯Œå±±çœŒ": "16",
        "çŸ³å·çœŒ": "17",
        "ç¦äº•çœŒ": "18",
        "å±±æ¢¨çœŒ": "19",
        "é•·é‡çœŒ": "20",
        "å²é˜œçœŒ": "21",
        "é™å²¡çœŒ": "22",
        "æ„›çŸ¥çœŒ": "23",
        "ä¸‰é‡çœŒ": "24",
        "æ»‹è³€çœŒ": "25",
        "äº¬éƒ½åºœ": "26",
        "å¤§é˜ªåºœ": "27",
        "å…µåº«çœŒ": "28",
        "å¥ˆè‰¯çœŒ": "29",
        "å’Œæ­Œå±±çœŒ": "30",
        "é³¥å–çœŒ": "31",
        "å³¶æ ¹çœŒ": "32",
        "å²¡å±±çœŒ": "33",
        "åºƒå³¶çœŒ": "34",
        "å±±å£çœŒ": "35",
        "å¾³å³¶çœŒ": "36",
        "é¦™å·çœŒ": "37",
        "æ„›åª›çœŒ": "38",
        "é«˜çŸ¥çœŒ": "39",
        "ç¦å²¡çœŒ": "40",
        "ä½è³€çœŒ": "41",
        "é•·å´çœŒ": "42",
        "ç†Šæœ¬çœŒ": "43",
        "å¤§åˆ†çœŒ": "44",
        "å®®å´çœŒ": "45",
        "é¹¿å…å³¶çœŒ": "46",
        "æ²–ç¸„çœŒ": "47"
    }
    
    print("\nPrefecture ID Mapping (JIS X 0401):")
    print("=" * 50)
    for name, code in prefecture_mapping.items():
        print(f"{code}: {name}")
    
    return prefecture_mapping

def test_mapping_against_data():
    """Test how well our mapping covers the existing data"""
    prefecture_counts = analyze_prefecture_data()
    prefecture_mapping = create_prefecture_mapping()
    
    print("\nMapping Coverage Analysis:")
    print("=" * 50)
    
    mapped = 0
    unmapped = 0
    
    for prefecture, count in prefecture_counts.items():
        if prefecture in prefecture_mapping:
            print(f"âœ… {prefecture} ({count} stations) -> {prefecture_mapping[prefecture]}")
            mapped += count
        else:
            print(f"âŒ {prefecture} ({count} stations) -> NO MAPPING")
            unmapped += count
    
    total = mapped + unmapped
    print(f"\nSummary:")
    print(f"Mapped: {mapped}/{total} stations ({mapped/total*100:.1f}%)")
    print(f"Unmapped: {unmapped}/{total} stations ({unmapped/total*100:.1f}%)")
    
    return prefecture_mapping

if __name__ == "__main__":
    mapping = test_mapping_against_data()
    
    print(f"\nğŸ” Prefecture extraction from Yahoo Transit pages:")
    print("From our analysis, we found prefecture mentions in page text:")
    print("- Shinjuku: 'æ±äº¬éƒ½', 'åŸ¼ç‰çœŒ' (multiple prefectures mentioned)")
    print("- Other pages may have prefecture info in breadcrumbs or structured data")
    print("\nRecommendation: Add prefecture_id field using JIS X 0401 codes")